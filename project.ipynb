{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['X', 'Y', 'OBJECTID', 'DOCUMENT_NBR', 'CRASH_YEAR', 'CRASH_DT',\n",
      "       'CRASH_MILITARY_TM', 'CRASH_SEVERITY', 'K_PEOPLE', 'A_PEOPLE',\n",
      "       'B_PEOPLE', 'C_PEOPLE', 'PERSONS_INJURED', 'PEDESTRIANS_KILLED',\n",
      "       'PEDESTRIANS_INJURED', 'VEH_COUNT', 'COLLISION_TYPE',\n",
      "       'WEATHER_CONDITION', 'LIGHT_CONDITION', 'ROADWAY_SURFACE_COND',\n",
      "       'RELATION_TO_ROADWAY', 'ROADWAY_ALIGNMENT', 'ROADWAY_SURFACE_TYPE',\n",
      "       'ROADWAY_DEFECT', 'ROADWAY_DESCRIPTION', 'INTERSECTION_TYPE',\n",
      "       'TRAFFIC_CONTROL_TYPE', 'TRFC_CTRL_STATUS_TYPE', 'WORK_ZONE_RELATED',\n",
      "       'WORK_ZONE_LOCATION', 'WORK_ZONE_TYPE', 'SCHOOL_ZONE',\n",
      "       'FIRST_HARMFUL_EVENT', 'FIRST_HARMFUL_EVENT_LOC', 'ALCOHOL_NOTALCOHOL',\n",
      "       'ANIMAL', 'BELTED_UNBELTED', 'BIKE_NONBIKE', 'DISTRACTED_NOTDISTRACTED',\n",
      "       'DROWSY_NOTDROWSY', 'DRUG_NODRUG', 'GR_NOGR', 'HITRUN_NOT_HITRUN',\n",
      "       'LGTRUCK_NONLGTRUCK', 'MOTOR_NONMOTOR', 'PED_NONPED', 'SPEED_NOTSPEED',\n",
      "       'SPEED_DIFF_MAX', 'RD_TYPE', 'INTERSECTION_ANALYSIS',\n",
      "       'SENIOR_NOTSENIOR', 'YOUNG_NOTYOUNG', 'MAINLINE_YN', 'NIGHT',\n",
      "       'VDOT_DISTRICT', 'JURIS_CODE', 'PHYSICAL_JURIS', 'FUN', 'FAC',\n",
      "       'AREA_TYPE', 'SYSTEM', 'VSP', 'OWNERSHIP', 'PLAN_DISTRICT', 'MPO_NAME',\n",
      "       'RTE_NM', 'RNS_MP', 'NODE', 'OFFSET'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "\n",
    "raw_data = pd.read_csv('data/Crash_Data.csv')\n",
    "\n",
    "#print(data.describe())\n",
    "print(raw_data.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns_list = [\n",
    "    'RNS_MP', \n",
    "    'PLAN_DISTRICT', \n",
    "    'MPO_NAME', \n",
    "    'NODE', \n",
    "    'OFFSET', \n",
    "    'VSP', \n",
    "    'JURIS_CODE', \n",
    "    'NIGHT', \n",
    "    'RD_TYPE',\n",
    "    'DOCUMENT_NBR', \n",
    "    'OBJECTID', \n",
    "    'CRASH_YEAR'\n",
    "]\n",
    "\n",
    "data = raw_data.drop(columns=columns_list)\n",
    "data['month'] = pd.to_datetime(data['CRASH_DT']).dt.strftime('%B')\n",
    "data = data.drop(columns=['CRASH_DT'])\n",
    "data = data.dropna(subset=['X', 'Y'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "numerical_columns = data.select_dtypes(include=[np.number]).columns\n",
    "categorical_columns = data.select_dtypes(include=['object']).columns\n",
    "\n",
    "\n",
    "num_pipeline = Pipeline([\n",
    "        ('imputer', SimpleImputer(strategy=\"median\")),\n",
    "        ('std_scaler', StandardScaler()),\n",
    "    ])\n",
    "\n",
    "full_pipeline = ColumnTransformer([\n",
    "        (\"num\", num_pipeline, numerical_columns),\n",
    "        (\"cat\", OneHotEncoder(handle_unknown='ignore'), categorical_columns),\n",
    "    ])\n",
    "\n",
    "data_prepared = full_pipeline.fit_transform(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "\n",
    "kmeans = KMeans(n_clusters=4, random_state=42)\n",
    "kmeans.fit(data_prepared)\n",
    "labels = kmeans.predict(data_prepared)\n",
    "centers = kmeans.cluster_centers_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1027064 entries, 0 to 1027063\n",
      "Data columns (total 2 columns):\n",
      " #   Column  Non-Null Count    Dtype  \n",
      "---  ------  --------------    -----  \n",
      " 0   X       1027051 non-null  float64\n",
      " 1   Y       1027051 non-null  float64\n",
      "dtypes: float64(2)\n",
      "memory usage: 15.7 MB\n",
      "None\n",
      "X    13\n",
      "Y    13\n",
      "dtype: int64\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "only integer scalar arrays can be converted to a scalar index",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mTypeError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[65]\u001b[39m\u001b[32m, line 16\u001b[39m\n\u001b[32m     13\u001b[39m pca = PCA(n_components=\u001b[32m2\u001b[39m)\n\u001b[32m     14\u001b[39m data_2d = pca.fit_transform(data_prepared)\n\u001b[32m---> \u001b[39m\u001b[32m16\u001b[39m x_min, x_max = np.min(\u001b[43mgeo_data\u001b[49m\u001b[43m[\u001b[49m\u001b[43mlabels\u001b[49m\u001b[43m \u001b[49m\u001b[43m==\u001b[49m\u001b[43m \u001b[49m\u001b[32;43m1\u001b[39;49m\u001b[43m:\u001b[49m\u001b[32;43m4\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[32;43m0\u001b[39;49m\u001b[43m]\u001b[49m), np.max(geo_data[:, \u001b[32m0\u001b[39m])\n\u001b[32m     17\u001b[39m y_min, y_max = np.min(geo_data[:, \u001b[32m1\u001b[39m]), np.max(geo_data[:, \u001b[32m1\u001b[39m])\n\u001b[32m     18\u001b[39m \u001b[38;5;28mprint\u001b[39m(x_min, x_max, y_min, y_max)\n",
      "\u001b[31mTypeError\u001b[39m: only integer scalar arrays can be converted to a scalar index"
     ]
    }
   ],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "\n",
    "geo_columns = ['X', 'Y']\n",
    "\n",
    "# Extract longitude and latitude before transformations\n",
    "geo_data = data[geo_columns].values\n",
    "\n",
    "print(data[geo_columns].info())\n",
    "print(data[geo_columns].isnull().sum())\n",
    "\n",
    "pca = PCA(n_components=2)\n",
    "data_2d = pca.fit_transform(data_prepared)\n",
    "\n",
    "x_min, x_max = np.min(geo_data[labels == 1:4, 0]), np.max(geo_data[:, 0])\n",
    "y_min, y_max = np.min(geo_data[:, 1]), np.max(geo_data[:, 1])\n",
    "print(x_min, x_max, y_min, y_max)\n",
    "\n",
    "# Plot clusters\n",
    "plt.figure(figsize=(24, 12))\n",
    "\n",
    "# Plot background image (map of VA)\n",
    "bg_map = mpimg.imread('./virginia_map.jpg')\n",
    "plt.imshow(bg_map, extent=[x_min, x_max, y_min, y_max], alpha=0.5, zorder=0)\n",
    "\n",
    "# Plot each cluster with a different color\n",
    "for i in range(4):\n",
    "    plt.scatter(geo_data[labels == i, 0], geo_data[labels == i, 1], \n",
    "                label=f'Cluster {i + 1}', alpha=0.6, s=10, zorder=1)\n",
    "\n",
    "# # Plot centroids\n",
    "# centers_2d = pca.transform(centers)\n",
    "# plt.scatter(centers[:, 0], centers[:, 1], s=300, c='red', marker='X', label='Centroids')\n",
    "\n",
    "# Read the image of California (make sure you have it in the directory)\n",
    "plt.title('K-Means Clustering with PCA (2D Projection)')\n",
    "plt.ylabel(\"Latitude\", fontsize=14)\n",
    "plt.xlabel(\"Longitude\", fontsize=14)\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "columns_list = [\n",
    "    'K_PEOPLE',\n",
    "    'A_PEOPLE',\n",
    "    'B_PEOPLE',\n",
    "    'C_PEOPLE',\n",
    "    'PERSONS_INJURED',\n",
    "    'PEDESTRIANS_KILLED',\n",
    "    'PEDESTRIANS_INJURED'\n",
    "]\n",
    "\n",
    "severity_mapping = {\n",
    "    'O': 0,  # property damage only\n",
    "    'C': 1,  # minor injury\n",
    "    'B': 2,  # medium injury\n",
    "    'A': 3,  # major injury\n",
    "    'K': 4   # death(s)\n",
    "}\n",
    "\n",
    "#data = data.drop(columns=columns_list)\n",
    "data['severity_num'] = data['CRASH_SEVERITY'].map(severity_mapping)\n",
    "train_set_prepared, test_set_prepared = train_test_split(data, test_size=0.2, random_state=42)\n",
    "\n",
    "X_train = train_set_prepared.drop('severity_num', axis=1)\n",
    "X_test = test_set_prepared.drop('severity_num', axis=1)\n",
    "y_train = train_set_prepared['severity_num']\n",
    "y_test = test_set_prepared['severity_num']\n",
    "\n",
    "data_class = full_pipeline.fit_transform(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "Index dimension must be 1 or 2",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mIndexError\u001b[39m                                Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[49]\u001b[39m\u001b[32m, line 6\u001b[39m\n\u001b[32m      2\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01msklearn\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mmetrics\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m classification_report, accuracy_score\n\u001b[32m      4\u001b[39m rf_clf = RandomForestClassifier(n_estimators=\u001b[32m100\u001b[39m, random_state=\u001b[32m42\u001b[39m)\n\u001b[32m----> \u001b[39m\u001b[32m6\u001b[39m rows_with_O = data_class[\u001b[43mdata_class\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mseverity_num\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m]\u001b[49m == \u001b[33m'\u001b[39m\u001b[33mO\u001b[39m\u001b[33m'\u001b[39m]\n\u001b[32m      8\u001b[39m rf_clf.fit(X_train, y_train)\n\u001b[32m      9\u001b[39m y_pred = rf_clf.predict(X_test)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/College/ML4VA/venv/lib/python3.11/site-packages/scipy/sparse/_index.py:30\u001b[39m, in \u001b[36mIndexMixin.__getitem__\u001b[39m\u001b[34m(self, key)\u001b[39m\n\u001b[32m     29\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m__getitem__\u001b[39m(\u001b[38;5;28mself\u001b[39m, key):\n\u001b[32m---> \u001b[39m\u001b[32m30\u001b[39m     index, new_shape = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_validate_indices\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     32\u001b[39m     \u001b[38;5;66;03m# 1D array\u001b[39;00m\n\u001b[32m     33\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(index) == \u001b[32m1\u001b[39m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/College/ML4VA/venv/lib/python3.11/site-packages/scipy/sparse/_index.py:288\u001b[39m, in \u001b[36mIndexMixin._validate_indices\u001b[39m\u001b[34m(self, key)\u001b[39m\n\u001b[32m    286\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:  \u001b[38;5;66;03m# dense array\u001b[39;00m\n\u001b[32m    287\u001b[39m     N = \u001b[38;5;28mself\u001b[39m._shape[index_ndim]\n\u001b[32m--> \u001b[39m\u001b[32m288\u001b[39m     idx = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_asindices\u001b[49m\u001b[43m(\u001b[49m\u001b[43midx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mN\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    289\u001b[39m     index.append(idx)\n\u001b[32m    290\u001b[39m     array_indices.append(index_ndim)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/College/ML4VA/venv/lib/python3.11/site-packages/scipy/sparse/_index.py:324\u001b[39m, in \u001b[36mIndexMixin._asindices\u001b[39m\u001b[34m(self, idx, length)\u001b[39m\n\u001b[32m    321\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mIndexError\u001b[39;00m(\u001b[33m'\u001b[39m\u001b[33minvalid index\u001b[39m\u001b[33m'\u001b[39m) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01me\u001b[39;00m\n\u001b[32m    323\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m x.ndim \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m (\u001b[32m1\u001b[39m, \u001b[32m2\u001b[39m):\n\u001b[32m--> \u001b[39m\u001b[32m324\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mIndexError\u001b[39;00m(\u001b[33m'\u001b[39m\u001b[33mIndex dimension must be 1 or 2\u001b[39m\u001b[33m'\u001b[39m)\n\u001b[32m    326\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m x.size == \u001b[32m0\u001b[39m:\n\u001b[32m    327\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m x\n",
      "\u001b[31mIndexError\u001b[39m: Index dimension must be 1 or 2"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "\n",
    "rf_clf = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "\n",
    "rows_with_O = data_class[data_class['severity_num'] == 'O']\n",
    "\n",
    "rf_clf.fit(X_train, y_train)\n",
    "y_pred = rf_clf.predict(X_test)\n",
    "print(rows_with_O)\n",
    "\n",
    "# Evaluate the classifier.\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(y_test, y_pred))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
